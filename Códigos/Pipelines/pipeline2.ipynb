{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ote_ZjMDIFDa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "torchaudio.set_audio_backend(\"sox_io\")\n",
        "\n",
        "# Carregar o modelo treinado e o processador\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"/content/command_processor\")\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"/content/command_model\").to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eavEfc-qIuYh"
      },
      "outputs": [],
      "source": [
        "def pad_waveform(waveform, target_length):\n",
        "    current_length = waveform.shape[1]\n",
        "    if current_length < target_length:\n",
        "        padding = target_length - current_length\n",
        "        waveform = torch.nn.functional.pad(waveform, (0, padding), \"constant\", 0)\n",
        "    return waveform\n",
        "\n",
        "def extract_features(audio_file, target_length=144648):  # Utilize o valor de LONGEST_LENGTH calculado anteriormente\n",
        "    waveform, sample_rate = torchaudio.load(audio_file)\n",
        "    waveform = pad_waveform(waveform, target_length)\n",
        "    input_values = processor(waveform.squeeze().numpy(), sampling_rate=sample_rate, return_tensors=\"pt\", padding=True).input_values\n",
        "    return input_values\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_values = [item[0] for item in batch]\n",
        "    labels = [item[1] for item in batch]\n",
        "    input_values = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
        "    labels = torch.tensor(labels)\n",
        "    return input_values, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ydhu4okIxFp"
      },
      "outputs": [],
      "source": [
        "class CommandDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.resampler = T.Resample(orig_freq=48000, new_freq=16000)\n",
        "        self.label_map = {cmd: idx for idx, cmd in enumerate(test_df['class'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.dataset.iloc[idx]['path']\n",
        "        command_class = self.dataset.iloc[idx]['class']\n",
        "        label = self.label_map.get(command_class, -1)\n",
        "        if label == -1:\n",
        "            raise ValueError(f\"Unknown class: {command_class}\")\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "        if sample_rate != 16000:\n",
        "            waveform = self.resampler(waveform)\n",
        "\n",
        "        input_values = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors='pt').input_values\n",
        "        return input_values.squeeze(), label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ7vaBpwIy-y"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"/content/test_data.csv\")\n",
        "\n",
        "test_dataset = CommandDataset(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvFFGYQEI1bW"
      },
      "outputs": [],
      "source": [
        "def evaluate_pipeline2(model, processor, dataloader, valid_commands):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            input_values, labels = batch\n",
        "            input_values = input_values.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(input_values)\n",
        "            logits = outputs.logits\n",
        "            predicted_ids = torch.argmax(logits, dim=-1)\n",
        "            end_time = time.time()\n",
        "\n",
        "            inference_times.append(end_time - start_time)\n",
        "            predictions.extend(predicted_ids.cpu().numpy())\n",
        "            references.extend(labels.cpu().numpy())\n",
        "\n",
        "    valid_label_map = {label: idx for idx, label in enumerate(valid_commands)}\n",
        "    reverse_label_map = {idx: label for label, idx in valid_label_map.items()}\n",
        "\n",
        "    valid_predictions = [reverse_label_map.get(p, \"DESCONHECIDO\") for p in predictions]\n",
        "    valid_references = [reverse_label_map.get(r, \"DESCONHECIDO\") for r in references]\n",
        "\n",
        "    filtered_predictions = [p for p in valid_predictions if p in valid_commands]\n",
        "    filtered_references = [r for r in valid_references if r in valid_commands]\n",
        "\n",
        "    report = classification_report(filtered_references, filtered_predictions, labels=valid_commands, zero_division=0)\n",
        "    mean_inference_time = np.mean(inference_times)\n",
        "    std_inference_time = np.std(inference_times)\n",
        "    unknown_commands_percentage = (valid_predictions.count(\"DESCONHECIDO\") / len(valid_predictions)) * 100\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(f\"Mean inference time: {mean_inference_time}\")\n",
        "    print(f\"Std inference time: {std_inference_time}\")\n",
        "    print(f\"Unknown commands: {unknown_commands_percentage:.2f}%\")\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "evaluate_pipeline2(model, processor, test_loader, test_df['class'].unique().tolist())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
